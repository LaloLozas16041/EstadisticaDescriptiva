{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "073480ba",
      "metadata": {
        "id": "073480ba"
      },
      "source": [
        "## 3.1 Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1371fea3",
      "metadata": {
        "id": "1371fea3"
      },
      "source": [
        "### Actividades básicas en el análisis estadístico"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7513684",
      "metadata": {
        "id": "c7513684"
      },
      "source": [
        "1. **Diseño del análisis**: Esta actividad involucra el planeamiento de los detalles para obtener los datos que necesitamos y la generación de la hipótesis a ser evaluada.\n",
        "$$\\newline$$\n",
        "2. **Exploración de datos**: En esta actividad nos dedicamos a jugar con nuestros datos, los describimos, los resumimos, realizamos gráficos para mirarlos desde distintos ángulos. Esta exploración nos ayuda a asegurarnos que los datos que obtuvimos son completos y que la etapa de diseño fue correcta.\n",
        "$$\\newline$$\n",
        "3. **Armado del modelo**: En esta actividad intentamos armar un modelo que explique el comportamiento de nuestros datos y pueda llegar a hacer predicciones sobre los mismos. La idea es que el modelo pueda describir las propiedades fundamentales de nuestros datos.\n",
        "$$\\newline$$\n",
        "4. **Realizar estimaciones**: Aquí vamos a intentar realizar estimaciones basadas en el modelo que armamos anteriormente. También vamos a intentar estimar el tamaño del error que nuestro modelo puede tener en sus predicciones.\n",
        "$$\\newline$$\n",
        "5. **Contraste de la hipótesis**: Esta actividad es la que va a producir la decisión final sobre si las predicciones del modelo son correctas y ayudarnos a concluir si los datos que poseemos confirman o rechazan la hipótesis que generamos en la actividad 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb326fd",
      "metadata": {
        "id": "ffb326fd"
      },
      "source": [
        "Librerías utilizadas para análisis estadístico"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5358309",
      "metadata": {
        "id": "e5358309"
      },
      "source": [
        "* numpy: El popular paquete matemático de Python, se utiliza tanto que mucha gente ya lo considera parte integral del lenguaje. Nos proporciona algunas funciones estadísticas que podemos aplicar fácilmente sobre los arrays de Numpy.\n",
        "---\n",
        "* scipy.stats: Este submodulo del paquete científico Scipy es el complemento perfecto para Numpy, las funciones estadisticas que no encontremos en uno, las podemos encontrar en el otro. $\\newline$\n",
        "* statsmodels: Esta librería nos brinda un gran número de herramientas para explorar datos, estimar modelos estadísticos, realizar pruebas estadísticas y muchas cosas más.\n",
        "$\\newline$\n",
        "* matplotlib: Es la librería más popular en Python para visualizaciones y gráficos. Ella nos va a permitir realizar los gráficos de las distintas distribuciones de datos.\n",
        "$\\newline$\n",
        "* seaborn: Esta librería es un complemento ideal de matplotlib para realizar gráficos estadísticos.\n",
        "$\\newline$\n",
        "* pandas: Esta es la librería más popular para análisis de datos y financieros. Posee algunas funciones muy útiles para realizar estadística descriptiva sobre nuestros datos y nos facilita sobremanera el trabajar con series de tiempo.\n",
        "$\\newline$\n",
        "* pyMC: pyMC es un módulo de Python que implementa modelos estadísticos bayesianos, incluyendo la cadena de Markov Monte Carlo(MCMC). pyMC ofrece funcionalidades para hacer el análisis bayesiano lo mas simple posible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cdc17f8",
      "metadata": {
        "id": "9cdc17f8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4027eebf",
      "metadata": {
        "id": "4027eebf"
      },
      "source": [
        "## 3.2 Ejemplo: Ánimo de twitteros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff1ebf36",
      "metadata": {
        "id": "ff1ebf36"
      },
      "source": [
        "¿Cómo se compara el ánimo de los twitteros por estado?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e998277",
      "metadata": {
        "id": "6e998277"
      },
      "source": [
        "1. Obtención y limpieza de tuits. Se pueden obtener los datos a través de una API, y la limpieza que se hace es por ejemplo, eliminar caracteres raros, emojis, abreviaciones, etc.\n",
        "\n",
        "2. Etiquetar los tuits en \"positivos\", \"negativos\", \"neutros\". Utilizan un algoritmo para etiquetar los tuits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8019ad47",
      "metadata": {
        "id": "8019ad47"
      },
      "outputs": [],
      "source": [
        "df_twitteros = pd.read_csv('./datos/animo_twitteros_semana.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aac27fa0",
      "metadata": {
        "id": "aac27fa0"
      },
      "outputs": [],
      "source": [
        "df_twitteros.groupby('lugar')['indice'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ac1790",
      "metadata": {
        "scrolled": false,
        "id": "79ac1790"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_twitteros, x=\"fecha\", y=\"indice\", color='lugar')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc703306",
      "metadata": {
        "id": "bc703306"
      },
      "source": [
        "## 3.3 Ejemplo: Precios de venta vivienda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a717b16",
      "metadata": {
        "id": "2a717b16"
      },
      "source": [
        "### Preguntas a responder\n",
        "\n",
        "1. ¿Es posible modelar el valor de la vivienda utilizando sus características?\n",
        "2. ¿Çómo varía el valor de la vivienda de estado a estado del país?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "654e0797",
      "metadata": {
        "id": "654e0797"
      },
      "source": [
        "#### Obtención de los datos\n",
        "\n",
        "1. Se utilizó web scrapping para obtener precios de ventas de casas y sus características\n",
        "2. Fue importante mantener el anonimato de la información\n",
        "3. Hubo una limpieza de información (obtener variables completas, evitar valores nulos, eliminar valores atípicos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd02411",
      "metadata": {
        "id": "0fd02411"
      },
      "source": [
        "#### Estructura de dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab232cba",
      "metadata": {
        "scrolled": true,
        "id": "ab232cba"
      },
      "outputs": [],
      "source": [
        "df_vivienda = pd.read_csv('./datos/precios_vivienda.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31871769",
      "metadata": {
        "id": "31871769"
      },
      "outputs": [],
      "source": [
        "df_vivienda.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "443966bc",
      "metadata": {
        "id": "443966bc"
      },
      "source": [
        "1. Si había valores ilógicos dentro de los registros, por ejemplo, casas con precios de 1 peso o con 100 habitaciones, o 1000 baños, se eliminaron los registros.\n",
        "\n",
        "Cuando tenemos registros atípicos o ilógicos o faltantes se puede hacer lo siguiente:\n",
        "\n",
        "* Eliminar el registro: solo aplica cuando la cantidad o naturaleza de los datos lo perminta\n",
        "* Imputación de datos: consiste en asignar un valor para reemplazar datos faltantes, o datos atípicos. Hay varias formas de imputar, por ejemplo, utilizando la media, la mediana o la moda. Otra forma es utilizando conocimientos del negocio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668d0f92",
      "metadata": {
        "id": "668d0f92"
      },
      "outputs": [],
      "source": [
        "print('Filas           :',df_vivienda.shape[0])\n",
        "print('Columnas        :',df_vivienda.shape[1])\n",
        "print('Valores con NA  :')\n",
        "print(df_vivienda.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4380906d",
      "metadata": {
        "id": "4380906d"
      },
      "outputs": [],
      "source": [
        "df_vivienda.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0944dd90",
      "metadata": {
        "id": "0944dd90"
      },
      "source": [
        "#### Exploración de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf72afa",
      "metadata": {
        "id": "9cf72afa"
      },
      "outputs": [],
      "source": [
        "fig = px.histogram(df_vivienda, x=\"Precio\", nbins=20)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664f9951",
      "metadata": {
        "id": "664f9951"
      },
      "outputs": [],
      "source": [
        "df_vivienda['log_precio'] = np.log(df_vivienda['Precio'])\n",
        "fig = px.histogram(df_vivienda, x=\"log_precio\", nbins=20)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fe5928",
      "metadata": {
        "id": "51fe5928"
      },
      "outputs": [],
      "source": [
        "df_vivienda.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c963b2",
      "metadata": {
        "id": "13c963b2"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(df_vivienda[df_vivienda['estados']=='GUERRERO'], x = 'build_area', y = 'log_precio')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8560aad",
      "metadata": {
        "id": "f8560aad"
      },
      "outputs": [],
      "source": [
        "df_comp = df_vivienda[(df_vivienda['estados']=='DISTRITO FEDERAL')|(df_vivienda['estados']=='GUERRERO')]\n",
        "fig = px.box(df_comp, x=\"estados\", y=\"Precio\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ac9eff",
      "metadata": {
        "id": "a8ac9eff"
      },
      "outputs": [],
      "source": [
        "resumen = df_vivienda.groupby(['estados'])['Precio'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad85674e",
      "metadata": {
        "id": "ad85674e"
      },
      "outputs": [],
      "source": [
        "resumen.sort_values('mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52116134",
      "metadata": {
        "id": "52116134"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7d9f013c",
      "metadata": {
        "id": "7d9f013c"
      },
      "source": [
        "Cuartiles - Nos da una idea de la distribución de los datos\n",
        "\n",
        "Q1 - Cuartil uno - 25%\n",
        "El 25% de los datos caen debajo de ese valor\n",
        "\n",
        "Q2 - Cuartil dos - 50%\n",
        "El 50% de los datos caen debajo de ese valor\n",
        "\n",
        "Q3 - Cuartil tres - 75%\n",
        "El 75% de los datos caen debajo de ese valor\n",
        "\n",
        "Datos = [0,0,0,0,0,0,0,0,0,100,1000]\n",
        "\n",
        "Media:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de9886d",
      "metadata": {
        "id": "6de9886d"
      },
      "outputs": [],
      "source": [
        "datos = [0,0,0,0,0,0,0,0,0,100,1000]\n",
        "datos2 = [100,100,100,100,100,100,100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e589cf92",
      "metadata": {
        "id": "e589cf92"
      },
      "outputs": [],
      "source": [
        "print(np.mean(datos))\n",
        "print(np.mean(datos2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893e2590",
      "metadata": {
        "id": "893e2590"
      },
      "outputs": [],
      "source": [
        "print(np.quantile(datos, [0.25,0.5,0.75]))\n",
        "print(np.quantile(datos2, [0.25,0.5,0.75]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a874c3e",
      "metadata": {
        "id": "6a874c3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dafecdf5",
      "metadata": {
        "id": "dafecdf5"
      },
      "source": [
        "## Modelo de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71eb4150",
      "metadata": {
        "id": "71eb4150"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592563af",
      "metadata": {
        "id": "592563af"
      },
      "outputs": [],
      "source": [
        "df_vivienda.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81d4576f",
      "metadata": {
        "id": "81d4576f"
      },
      "outputs": [],
      "source": [
        "df_vivienda.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22662ac0",
      "metadata": {
        "id": "22662ac0"
      },
      "outputs": [],
      "source": [
        "def tidy_corr_matrix(corr_mat):\n",
        "    '''\n",
        "    Función para convertir una matriz de correlación de pandas en formato tidy\n",
        "    '''\n",
        "    corr_mat = corr_mat.stack().reset_index()\n",
        "    corr_mat.columns = ['variable_1','variable_2','r']\n",
        "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
        "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
        "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
        "\n",
        "    return(corr_mat)\n",
        "\n",
        "\n",
        "\n",
        "corr_matrix = df_vivienda.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
        "tidy_corr_matrix(corr_matrix).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2faaf909",
      "metadata": {
        "id": "2faaf909"
      },
      "outputs": [],
      "source": [
        "df_vivienda.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d041ff1a",
      "metadata": {
        "id": "d041ff1a"
      },
      "outputs": [],
      "source": [
        "# División de los datos en train y test\n",
        "# ==============================================================================\n",
        "X = df_vivienda[['build_area', 'bedrooms','garages', 'Pisos', 'Publicacion']]\n",
        "y = df_vivienda['log_precio']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                        X,\n",
        "                                        y.values.reshape(-1,1),\n",
        "                                        train_size   = 0.8,\n",
        "                                        random_state = 1234,\n",
        "                                        shuffle      = True\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b71b92",
      "metadata": {
        "id": "16b71b92"
      },
      "outputs": [],
      "source": [
        "# Creación del modelo utilizando matrices como en scikitlearn\n",
        "# ==============================================================================\n",
        "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
        "X_train = sm.add_constant(X_train, prepend=True)\n",
        "modelo = sm.OLS(endog=y_train, exog=X_train,)\n",
        "modelo = modelo.fit()\n",
        "print(modelo.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523b86e1",
      "metadata": {
        "id": "523b86e1"
      },
      "outputs": [],
      "source": [
        "# Intervalos de confianza para los coeficientes del modelo\n",
        "# ==============================================================================\n",
        "intervalos_ci = modelo.conf_int(alpha=0.05)\n",
        "intervalos_ci.columns = ['2.5%', '97.5%']\n",
        "intervalos_ci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e33ec3",
      "metadata": {
        "id": "53e33ec3"
      },
      "outputs": [],
      "source": [
        "# Diagnóstico errores (residuos) de las predicciones de entrenamiento\n",
        "# ==============================================================================\n",
        "y_train = y_train.flatten()\n",
        "prediccion_train = modelo.predict(exog = X_train)\n",
        "residuos_train   = prediccion_train - y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2a7743",
      "metadata": {
        "scrolled": true,
        "id": "0a2a7743"
      },
      "outputs": [],
      "source": [
        "# Gráficos\n",
        "# ==============================================================================\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 8))\n",
        "\n",
        "axes[0, 0].scatter(y_train, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)\n",
        "axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()],\n",
        "                'k--', color = 'black', lw=2)\n",
        "axes[0, 0].set_title('Valor predicho vs valor real', fontsize = 10, fontweight = \"bold\")\n",
        "axes[0, 0].set_xlabel('Real')\n",
        "axes[0, 0].set_ylabel('Predicción')\n",
        "axes[0, 0].tick_params(labelsize = 7)\n",
        "\n",
        "axes[0, 1].scatter(list(range(len(y_train))), residuos_train,\n",
        "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
        "axes[0, 1].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
        "axes[0, 1].set_title('Residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
        "axes[0, 1].set_xlabel('id')\n",
        "axes[0, 1].set_ylabel('Residuo')\n",
        "axes[0, 1].tick_params(labelsize = 7)\n",
        "\n",
        "sns.histplot(\n",
        "    data    = residuos_train,\n",
        "    stat    = \"density\",\n",
        "    kde     = True,\n",
        "    line_kws= {'linewidth': 1},\n",
        "    color   = \"firebrick\",\n",
        "    alpha   = 0.3,\n",
        "    ax      = axes[1, 0]\n",
        ")\n",
        "\n",
        "axes[1, 0].set_title('Distribución residuos del modelo', fontsize = 10,\n",
        "                     fontweight = \"bold\")\n",
        "axes[1, 0].set_xlabel(\"Residuo\")\n",
        "axes[1, 0].tick_params(labelsize = 7)\n",
        "\n",
        "\n",
        "sm.qqplot(\n",
        "    residuos_train,\n",
        "    fit   = True,\n",
        "    line  = 'q',\n",
        "    ax    = axes[1, 1],\n",
        "    color = 'firebrick',\n",
        "    alpha = 0.4,\n",
        "    lw    = 2\n",
        ")\n",
        "axes[1, 1].set_title('Q-Q residuos del modelo', fontsize = 10, fontweight = \"bold\")\n",
        "axes[1, 1].tick_params(labelsize = 7)\n",
        "\n",
        "axes[2, 0].scatter(prediccion_train, residuos_train,\n",
        "                   edgecolors=(0, 0, 0), alpha = 0.4)\n",
        "axes[2, 0].axhline(y = 0, linestyle = '--', color = 'black', lw=2)\n",
        "axes[2, 0].set_title('Residuos del modelo vs predicción', fontsize = 10, fontweight = \"bold\")\n",
        "axes[2, 0].set_xlabel('Predicción')\n",
        "axes[2, 0].set_ylabel('Residuo')\n",
        "axes[2, 0].tick_params(labelsize = 7)\n",
        "\n",
        "# Se eliminan los axes vacíos\n",
        "fig.delaxes(axes[2,1])\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.subplots_adjust(top=0.9)\n",
        "fig.suptitle('Diagnóstico residuos', fontsize = 12, fontweight = \"bold\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c41df3c",
      "metadata": {
        "id": "2c41df3c"
      },
      "outputs": [],
      "source": [
        "# Normalidad de los residuos Shapiro-Wilk test\n",
        "# ==============================================================================\n",
        "shapiro_test = stats.shapiro(residuos_train)\n",
        "shapiro_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b6a67df",
      "metadata": {
        "id": "9b6a67df"
      },
      "outputs": [],
      "source": [
        "# Error de test del modelo\n",
        "# ==============================================================================\n",
        "X_test = sm.add_constant(X_test, prepend=True)\n",
        "predicciones = modelo.predict(exog = X_test)\n",
        "rmse = mean_squared_error(\n",
        "        y_true  = y_test,\n",
        "        y_pred  = predicciones,\n",
        "        squared = False\n",
        "       )\n",
        "print(\"\")\n",
        "print(f\"El error (rmse) de test es: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78834bdf",
      "metadata": {
        "id": "78834bdf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}